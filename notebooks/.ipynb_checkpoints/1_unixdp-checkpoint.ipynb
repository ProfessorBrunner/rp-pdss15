{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "\n",
    "# Unix Data Processing\n",
    "## Professor Robert J. Brunner\n",
    "  \n",
    "</DIV>  \n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unix Data Procesing Overview\n",
    "\n",
    "The purpose of this class is to introduce practical data science comcepts. The Unix operating system and its rich set of commands have been in existence for a number of years. When they were first developed, data sets were generally much larger than the available compute resources. As we now find ourselve in a similar siutation, these commands remain extremely useful. Furthermore, since a lot of data processing can most easily be done directly on the data as it resides on the file system (to minimize data transfer and other overheads), hacing familiarity with these commands can prove extremely useful.\n",
    "\n",
    "Overall, we will explore Unix commands for data processing that can be categorized in the following ways:\n",
    "\n",
    "- Viewing data\n",
    "- Basic data processing\n",
    "- Finding data\n",
    "- Tranforming data\n",
    "- Advanced data processing\n",
    "\n",
    "Basic data processing refers to simple operations on a data file, including sort, finding unique or duplicate lines, counting the number of lines in a file, joining two files, or extracting columns from a file. Advanced data processing refers to performing simple or complicated operations on data in a file, where the operation may change depending on valus in the file itself. Finally, we will breifly discuss Shell scripting to these data processing tasks more permenant.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing data\n",
    "\n",
    "An important task we will cover first is how to actually view the\n",
    "contents of a file. In a graphical interface, you would open a document\n",
    "editor, such as Microsoft Word, and then load the file into your editor.\n",
    "At the command line, however, we simply use  a Unix command to open a\n",
    "file for reading and to display the contents of a file to `stdout`,\n",
    "which is generally the screen. When constructing Unix pipes, however, we\n",
    "can use a file viewer at the start of the pipeline and pipe `stdout` \n",
    "into the next command in the chain.\n",
    "\n",
    "Several commands are useful for viewing files:\n",
    "\n",
    "### [`cat`][1]\n",
    "\n",
    "Used to view the entire contents of a file. For example, to send the\n",
    "contents of myfile to `stdout`, which in this case is the terminal\n",
    "display:\n",
    "\n",
    "    $ cat myfile\n",
    "    \n",
    "### [`less`][2]\n",
    "\n",
    "Used to view the contents of a file, one screen at a time. Additional\n",
    "options are available, that can be changed while viewing the file,\n",
    "providing a lot of flexibility. `less` is a more recent version of the\n",
    "`more` command, which can also be used. For example, to page through the\n",
    "contents of myfile (using the spacebar to go to the next screen, or the\n",
    "`b` key to go back one screen):\n",
    "\n",
    "    $ less myfile\n",
    "   \n",
    "### [`head`][3]\n",
    "\n",
    "Used to view a limited number of lines from the start (or head) of the\n",
    "file. By default the first ten lines will be displayed, but you can\n",
    "specify the exact number by using the `-n num` flag, where _num_ is the\n",
    "number of lines to display. For example, to display the first five lines\n",
    "from myfile:\n",
    "\n",
    "    $ head -5 myfile\n",
    "\n",
    "### [`tail`][4]\n",
    "\n",
    "Used to view a limited number of lines from the end (or tail) of the\n",
    "file. By default the first ten lines will be displayed, but you can\n",
    "specify the exact number by using the `-n num` flag, where _num_ is the\n",
    "number of lines to display. For example, to display the last three lines\n",
    "from myfile:\n",
    "\n",
    "\n",
    "    $ tail -3 myfile\n",
    "\n",
    "Another useful option for the `tail` command is the `-f` flag, which can\n",
    "be used to display the last lines of a file that might be continually\n",
    "updated (e.g., the output of another command).\n",
    "\n",
    "We can demonstrate several of these commands, by first grabbing some\n",
    "data (as indicated in the Unix Networking lesson) and viewing part of\n",
    "the data.\n",
    "\n",
    "![Viewing data example](images/shell-view.png)\n",
    "\n",
    "-----\n",
    "[1]: https://en.wikipedia.org/wiki/Cat_(Unix)\n",
    "[2]: https://en.wikipedia.org/wiki/Less_(Unix)\n",
    "[3]: https://en.wikipedia.org/wiki/Head_(Unix)\n",
    "[4]: https://en.wikipedia.org/wiki/Tail_(Unix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple data processing\n",
    "\n",
    "A number of simple Unix commands exist to perform basic data processing\n",
    "tasks, like sorting, eliminating duplicate lines, counting lines, and\n",
    "joining files together or splitting files apart.\n",
    "\n",
    "### [`sort`][1]\n",
    "\n",
    "Used to sort the contents of a file alphabetically. The field, or\n",
    "column, that should be used as the sort key is specified by the `-k`\n",
    "flag, by default the first column is used. A numeric sorting can be\n",
    "indicated by using the `-n` flag can be used. the entire contents of a\n",
    "file. For example, to sort the contents of myfile numerically, using the\n",
    "third column, we can use the following command:\n",
    "\n",
    "    $ sort -n -k 3 myfile\n",
    "\n",
    "### [`uniq`][2] \n",
    "\n",
    "Used to view only uniq lines in a file, the lines must be adjacent to be\n",
    "considered unique. Thus, this command is often used in a pipe after a\n",
    "sort so that matching lines are adjacent. For example, to display only\n",
    "the unique lines in a myfile that has been sorted, we can use the\n",
    "following command:\n",
    "\n",
    "    $ uniq myfile\n",
    "\n",
    "### [`wc`][3]\n",
    "\n",
    "Used to count the number of words and/or lines in a file (or set of\n",
    "files). One common use of `wc` is to display the number of lines in a\n",
    "file, which is done by using the `-l` flag. For example, to count and\n",
    "display the number of lines in myfile, we can use the following command:\n",
    "\n",
    "    $ wc -l myfile\n",
    "\n",
    "-----\n",
    "\n",
    "Three other related Unix commands can be useful for simple data\n",
    "processing, especially as part of a Unix Pipeline. These are the\n",
    "[`paste`], the [`join`], and the [`cut`] commands. The `paste` command\n",
    "is used to connect lines from multiple files.  The second command is\n",
    "similar, but `join` will connect lines that match have matching entries.\n",
    "Finally, the third command cuts part of a file to display. \n",
    "\n",
    "### [`paste`][4]\n",
    "\n",
    "Generally used to combine two files together by pasting _row1_ from the\n",
    "second file  to the end of _row1_ in the first file. This process\n",
    "continues until all rows have been pasted. For example, to paste the two\n",
    "files, myfile1 and myfile2 together, we can use the following command:\n",
    "\n",
    "    $ paste myfile1 myfile2\n",
    "\n",
    "### [`join`][5]\n",
    "\n",
    "Used to combine only the rows from two files that have matching entries\n",
    "in a specific column, in a similar manner to a database join (both\n",
    "inner, the default, and outer joins are supported). The columns can be\n",
    "different for each file, and are specified by using flags: `-1`, to\n",
    "refer to the field position in the first file, and `-2`, to refer to the\n",
    "field position in the second file. For example, to perform an inner join\n",
    "for rows from myfile1 and myfile2 where the second column in myfile1\n",
    "matches the fifth column in myfile2, we can use the following command:\n",
    "\n",
    "    $ join -1 2 -2 5 myfile1 myfile2\n",
    "\n",
    "### [`cut`][6]\n",
    "\n",
    "Used to select only part of a each row for display. The part to cut can\n",
    "be specified as either specific numbers of characters or bytes, or the\n",
    "rows can be split on a delimiter value and only select fields (or\n",
    "columns) will be displayed. For example, to display only the third\n",
    "through the fifth fields from a CSV file, we can use the following\n",
    "command:\n",
    "\n",
    "    $ cut -d \",\" -f 3-5 myfile.csv\n",
    "\n",
    "\n",
    "-----\n",
    "[1]: https://en.wikipedia.org/wiki/Sort_(Unix)\n",
    "[2]: https://en.wikipedia.org/wiki/Uniq\n",
    "[3]: https://en.wikipedia.org/wiki/Wc_(Unix)\n",
    "[4]: https://en.wikipedia.org/wiki/Paste_(Unix)\n",
    "[5]: https://en.wikipedia.org/wiki/Join_(Unix)\n",
    "[6]: https://en.wikipedia.org/wiki/Cut_(Unix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding data\n",
    "\n",
    "A common data processing task is to find information, which can be even\n",
    "more difficult in a big data environment. Unix offeres several commands\n",
    "that are designed to quickly find relavant information.\n",
    "\n",
    "### [`grep`][1]\n",
    "\n",
    "One common task is searching for a pattern within a stream of data. On a\n",
    "Unix system, we can use the `grep` command to search for a pattern in\n",
    "one more files. Formally, the pattern can be a [regular\n",
    "expression](http://www.aboutlinux.info/2006/01/learn-how-to-use-regular-\n",
    "expressions.html), allowing for complicated pattern matching. Any row in\n",
    "the file (or list of files) supplied to grep that match the target\n",
    "pattern are written to `stdout`, which typically means displayed to the\n",
    "terminal.\n",
    "\n",
    "A typical use of `grep` is to output lines from a file that match the\n",
    "target pattern. For example, to print out all rows in myfile that\n",
    "contain _Illinois_, we can use the following command:\n",
    "\n",
    "    $ grep Illinois myfile\n",
    "\n",
    "### [`which`][2]\n",
    "\n",
    "In some cases, we need to know where a a program is located in the Unix\n",
    "filesystem. This can be useful when multiple versions of an executable\n",
    "might exist. We can find the location of a particular command or program\n",
    "by using the `which` command. For example, to find the directory in\n",
    "which the `which` command is located, we can use the following command:\n",
    "\n",
    "    $ which which\n",
    "\n",
    "### [`find`][3]\n",
    "\n",
    "A more general case is where we might need to find one or more files\n",
    "within a large file system. The standard tool used to accomplish this on\n",
    "a Unix system is the `find` command. The `find` command is extremely\n",
    "powerful, as you can recursively traverse directoires to find files that\n",
    "match a pattern, and then perform some option based on the results. This\n",
    "can include simply listing the full pathnames of the files to performing\n",
    "some complicated processing task on the located files (like renaming the\n",
    "files). For example, to find and list all files located within the\n",
    "current directory that have the word _illinois_ somewhere in the\n",
    "filename, we can use the following command:\n",
    "\n",
    "    $ find *illinois* -print\n",
    "\n",
    "here the `*` charachters signify that any pattern is matched, allowing\n",
    "any filename with illinois anywhere in the filename to be identified.\n",
    "\n",
    "-----\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Grep\n",
    "[2]: https://en.wikipedia.org/wiki/Which_(Unix)\n",
    "[3]: https://en.wikipedia.org/wiki/Find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data\n",
    "\n",
    "To transform data we can use the stream editor, or\n",
    "[`sed`](https://en.wikipedia.org/wiki/Sed). Sed provides an easy\n",
    "mechanism for the find-and-replace approach of data processing,\n",
    "line-by-line through a file. A `sed` command is more flexible, however,\n",
    "and it can also be used to filter data as part of a Unix pipe sequence.\n",
    "By default, `sed` processes a stream of data read from `stdin` and\n",
    "writes the possibly transformed data top `stdout`.\n",
    "\n",
    "We can summarize the general format of a substitution `sed` command:\n",
    "\n",
    "    sed 's/pattern/replacement/g' myfile\n",
    "\n",
    "where the `s` indicates a substitution will occur, `pattern` is the text\n",
    "to find, which can include a [regular\n",
    "expression](http://www.aboutlinux.info/2006/01/learn-how-to-use-regular-\n",
    "expressions.html), `replacement` is the text to substitute in place of\n",
    "the pattern, and the `g` indicates that every occurrence of the `pattern`\n",
    "on the line should be replaced. For example, if we want to transform a\n",
    "comma-separated value file to use two spaces instead of commas to\n",
    "separate fields, we could use the following `sed` command:\n",
    "\n",
    "    $ sed 's/,/ /g' myfile.csv\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data\n",
    "\n",
    "A simple technique to perform simple data processing of large data files\n",
    "on a Unix system is to use the [Awk](https://en.wikipedia.org/wiki/AWK)\n",
    "programming language. We will generally write a short, inline `awk`\n",
    "command to performa simple processing, however, we could write complex\n",
    "`awk` programs that are saved in their own text file.\n",
    "\n",
    "The general format of an `awk` program is pre-processing, a per-line\n",
    "processing, and post-processing. The pre-processing is contained within\n",
    "the `BEGIN{ ... }` clause, while the post-processing is contained within\n",
    "the `END { ... }` clause. The per-line processing occurs in the\n",
    "central `{ ... }` clause. Both the pre- and post-processing are optional.\n",
    "\n",
    "For example, if we want to print out only the first, third and sixth\n",
    "columns of every row in `myfile`, we can use the following `awk` command:\n",
    "\n",
    "    $ awk '{print $1, $3, $6 ; }' myfile\n",
    "\n",
    "We also can selectively process only rows that meet a certain condition.\n",
    "For example, to print out the entire row when the first column is\n",
    "greater than ten, we can use the following `awk` command::\n",
    "\n",
    "\n",
    "    $ awk '{if ($1 > 10) print $0 ; }' myfile\n",
    "\n",
    "where we have used the fact that `$0` is a special variable that\n",
    "contains the entire row data.\n",
    "\n",
    "Another useful trick is to accumulate a running sum from one or more\n",
    "columns, and print the result out after processing an entire file:\n",
    "\n",
    "    $ awk 'BEGIN {sum = 0}{sum += $3 } END {print sum}' myfile\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Shell Scripting\n",
    "\n",
    "The Bash shell provides a full scripting capability, including the use\n",
    "of variables, expression, loops, and conditionals. While a full\n",
    "discussion on Bash shell scripting is beyond the scope of this lesson,\n",
    "it is often useful to take an existing data processing command sequence\n",
    "and turn it into a simple script. This can provide several benefits.\n",
    "First, by using comments to document the script, you have a documented\n",
    "shell command sequence. Second, by creating a simple script, you can\n",
    "often increase the functionality of your data processing, for example,\n",
    "by allowing arbitrary filenames for the input and output of the command.\n",
    "\n",
    "When creating a simple Bash shell script there are several useful things\n",
    "to keep in mind.\n",
    "\n",
    "1. The first line of the file should start with the special sequence\n",
    "`#!/bin/bash` which signifies this script should be run via the bash\n",
    "shell.  \n",
    "2. Comment lines start with the hash `#` character.  \n",
    "3. Command line parameters are available as special variables encoded by\n",
    "`$D` where D is a decimal integer. For example, the first argument is\n",
    "`$1`.  \n",
    "4. The shell script must have execute permission set for the current\n",
    "user (either via owner, group, or all).  \n",
    "\n",
    "For example, to turn our `sed` script that converted a csv file into a\n",
    "whitespace separated file, we can create the following shell script that\n",
    "we call test.sh:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#\n",
    "# Convert the CSV file read from STDIN to a white space separated file on STDOUT\n",
    "\n",
    "sed 's/,/  /g' $1\n",
    "```\n",
    "\n",
    "To use this script, we first need to make the script executable:\n",
    "    $ chmod u+x ./test.sh\n",
    "    \n",
    "Next, we can execute this script as shown in the following image:\n",
    "\n",
    "![shell script example](images/shell-script.png)\n",
    "\n",
    "Notice how we first display two lines, and next convert only these two\n",
    "lins to whitespace separated values.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional References\n",
    "\n",
    "1. Why a data scientist should be familiar with the [command line](http://www.dataists.com/2010/09/a-taxonomy-of-data-science/)\n",
    "2. The book on [Data Science at the Command Line](http://datascienceatthecommandline.com)\n",
    "2. A detailed discussion on [regular expressions](http://en.wikipedia.org/wiki/Regular_expression#Basic_concepts).\n",
    "3. [AWK Tutorial](http://www.thelinuxtips.com/2012/03/awk-basics-tutorial-1/)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to the [Course Index](index.ipynb).\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
